{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "-EveXIp8R-f1",
      "metadata": {
        "id": "-EveXIp8R-f1"
      },
      "source": [
        "# Build a Reflective Self-Correcting Code Generation AI Agent\n",
        "\n",
        "In this project we will be building an intelligent self-correction code generation AI Agent which can generate working code for user problems, leverage the reflection pattern to examine and test the code and improve and correct it.\n",
        "\n",
        "![](https://i.imgur.com/koLDCZL.png)\n",
        "\n",
        "### Reflective Self-Correcting Code Generation AI Agent\n",
        "\n",
        "This project focuses on building a **Reflective Self-Correcting Code Generation AI Agent**, designed to iteratively generate, execute, and refine code to achieve accurate solutions. The workflow integrates reflective reasoning and error analysis to ensure robust and functional code generation. The workflow includes the following components:\n",
        "\n",
        "1. **Code Generation**:\n",
        "   - The system utilizes **OpenAI GPT-4o** to generate code based on the user's input and problem requirements.\n",
        "   - Code is generated following a predefined schema, including:\n",
        "     - **Prefix**: Problem description or setup requirements.\n",
        "     - **Imports**: Necessary libraries or dependencies.\n",
        "     - **Code**: Functional implementation of the solution.\n",
        "\n",
        "2. **Code Execution and Reflection**:\n",
        "   - The generated code is executed, and the results are analyzed.\n",
        "   - If an error occurs, feedback is provided to refine the code:\n",
        "     - **Error Feedback**: Captures errors or unexpected behaviors during execution.\n",
        "     - **Reflection**: GPT-4o reflects on the error feedback to iteratively improve the solution.\n",
        "\n",
        "3. **Iterative Correction Loop**:\n",
        "   - The system repeats the generate-execute-reflect cycle until:\n",
        "     - A successful solution is achieved (no errors).\n",
        "     - The attempt count exceeds a predefined threshold (`N`), ensuring the loop terminates if a solution cannot be reached.\n",
        "\n",
        "4. **Attempt Counter**:\n",
        "   - Tracks the number of attempts (`K`) and increments with each iteration.\n",
        "   - If the attempt count exceeds the predefined threshold, the process halts, and the user is informed.\n",
        "\n",
        "5. **Final Validation**:\n",
        "   - Once the code passes execution without errors, the refined solution is presented to the user as the final output.\n",
        "\n",
        "6. **User Feedback Loop**:\n",
        "   - If the user is unsatisfied with the solution, the process can be restarted to refine the code further or adjust the requirements.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9hEI3WL328vZ",
      "metadata": {
        "id": "9hEI3WL328vZ"
      },
      "source": [
        "## Install OpenAI, LangGraph and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "avUQykrKR-f3",
      "metadata": {
        "id": "avUQykrKR-f3"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain==0.3.14\n",
        "# !pip install langchain-openai==0.3.0\n",
        "# !pip install langchain-community==0.3.14\n",
        "# !pip install langgraph==0.2.64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e927e8f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oVQrgISwSMot",
      "metadata": {
        "id": "oVQrgISwSMot"
      },
      "source": [
        "## Enter LLM Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "daf0feab",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_llm():\n",
        "    return ChatOpenAI(\n",
        "        model=\"openai/gpt-oss-20b\",          \n",
        "        temperature=0,\n",
        "        api_key=\"EMPTY\",              \n",
        "        base_url=\"http://localhost:5005/v1\",\n",
        "    )\n",
        "\n",
        "llm = get_llm()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y0QSiCCsR-f6",
      "metadata": {
        "id": "Y0QSiCCsR-f6"
      },
      "source": [
        "## Build Code Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ucT0JZHR-f6",
      "metadata": {
        "id": "0ucT0JZHR-f6"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# Prompt\n",
        "CODE_GEN_SYS_PROMPT = [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are a coding assistant.\n",
        "                Ensure any code you provide can be executed with all required imports and variables defined.\n",
        "                Make sure point 3 below has some code to run and execute any code or functions which you define\n",
        "\n",
        "                Structure your answer as follows:\n",
        "                  1) a prefix describing the code solution\n",
        "                  2) the imports (if no imports needed keep it empty string)\n",
        "                  3) the functioning code blocks\n",
        "\n",
        "                Here is the user question:\"\"\",\n",
        "        )\n",
        "]\n",
        "\n",
        "# Data model\n",
        "class Code(BaseModel):\n",
        "    \"\"\"Schema for code solutions to questions about coding.\"\"\"\n",
        "\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Just the import statements of the code\")\n",
        "    code: str = Field(description=\"Code blocks not including import statements\")\n",
        "\n",
        "# LLM\n",
        "code_generator = llm.with_structured_output(Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "TGeNQYjDTMwY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGeNQYjDTMwY",
        "outputId": "67df01ec-9af5-4eda-c161-c6e60f860862"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Code(prefix='Here is a simple, self‑contained Python implementation that generates the Fibonacci series. It includes a function to return the first *n* terms, a generator version for lazy evaluation, and a small demo that prints the first 10 numbers.', imports='# No external imports are required\\n', code='# Function that returns the first n Fibonacci numbers as a list\\n\\ndef fibonacci_list(n: int) -> list[int]:\\n    \"\"\"Return a list containing the first *n* Fibonacci numbers.\\n\\n    Parameters\\n    ----------\\n    n : int\\n        The number of terms to generate. Must be non‑negative.\\n\\n    Returns\\n    -------\\n    list[int]\\n        A list of the first *n* Fibonacci numbers.\\n    \"\"\"\\n    if n < 0:\\n        raise ValueError(\"n must be non‑negative\")\\n    if n == 0:\\n        return []\\n    if n == 1:\\n        return [0]\\n\\n    fib_seq = [0, 1]\\n    while len(fib_seq) < n:\\n        fib_seq.append(fib_seq[-1] + fib_seq[-2])\\n    return fib_seq\\n\\n# Generator that yields Fibonacci numbers indefinitely\\n\\ndef fibonacci_generator():\\n    \"\"\"Yield Fibonacci numbers one by one.\\n\\n    This generator can be used in a loop or with ``itertools.islice`` to\\n    obtain a finite number of terms.\\n    \"\"\"\\n    a, b = 0, 1\\n    while True:\\n        yield a\\n        a, b = b, a + b\\n\\n# Demo: print the first 10 Fibonacci numbers\\nif __name__ == \"__main__\":\\n    n_terms = 10\\n    print(f\"First {n_terms} Fibonacci numbers (list):\", fibonacci_list(n_terms))\\n\\n    # Using the generator to get the same result\\n    from itertools import islice\\n    print(\\n        f\"First {n_terms} Fibonacci numbers (generator):\",\\n        list(islice(fibonacci_generator(), n_terms)),\\n    )\\n')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"How to create fibonacci series\"\n",
        "messages = [(\"user\", question)]\n",
        "\n",
        "result = code_generator.invoke(CODE_GEN_SYS_PROMPT + messages)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "iwqUwqtIThC2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwqUwqtIThC2",
        "outputId": "88b32052-851e-4d15-e949-54b49bcb95e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Function that returns the first n Fibonacci numbers as a list\n",
            "\n",
            "def fibonacci_list(n: int) -> list[int]:\n",
            "    \"\"\"Return a list containing the first *n* Fibonacci numbers.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    n : int\n",
            "        The number of terms to generate. Must be non‑negative.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    list[int]\n",
            "        A list of the first *n* Fibonacci numbers.\n",
            "    \"\"\"\n",
            "    if n < 0:\n",
            "        raise ValueError(\"n must be non‑negative\")\n",
            "    if n == 0:\n",
            "        return []\n",
            "    if n == 1:\n",
            "        return [0]\n",
            "\n",
            "    fib_seq = [0, 1]\n",
            "    while len(fib_seq) < n:\n",
            "        fib_seq.append(fib_seq[-1] + fib_seq[-2])\n",
            "    return fib_seq\n",
            "\n",
            "# Generator that yields Fibonacci numbers indefinitely\n",
            "\n",
            "def fibonacci_generator():\n",
            "    \"\"\"Yield Fibonacci numbers one by one.\n",
            "\n",
            "    This generator can be used in a loop or with ``itertools.islice`` to\n",
            "    obtain a finite number of terms.\n",
            "    \"\"\"\n",
            "    a, b = 0, 1\n",
            "    while True:\n",
            "        yield a\n",
            "        a, b = b, a + b\n",
            "\n",
            "# Demo: print the first 10 Fibonacci numbers\n",
            "if __name__ == \"__main__\":\n",
            "    n_terms = 10\n",
            "    print(f\"First {n_terms} Fibonacci numbers (list):\", fibonacci_list(n_terms))\n",
            "\n",
            "    # Using the generator to get the same result\n",
            "    from itertools import islice\n",
            "    print(\n",
            "        f\"First {n_terms} Fibonacci numbers (generator):\",\n",
            "        list(islice(fibonacci_generator(), n_terms)),\n",
            "    )\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(result.code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "qxkRKJuh2mXX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxkRKJuh2mXX",
        "outputId": "f8b37fb1-5e07-47cb-e80f-ba491c23c10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# No external imports are required\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(result.imports)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wREDcQKQR-f7",
      "metadata": {
        "id": "wREDcQKQR-f7"
      },
      "source": [
        "We create a chain that returns structured data for code solutions. We’ll feed it the user’s question plus the system directive in the prompt above."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YZ1pviPJR-f7",
      "metadata": {
        "id": "YZ1pviPJR-f7"
      },
      "source": [
        "## Build Agent Graph Node Functions\n",
        "\n",
        "The key focus here will be to create the function implementations of the main nodes in our graph which will include:\n",
        "\n",
        "-  **Generate** a code solution\n",
        "-  **Check code** imports and code execution and add error messages if any\n",
        "- **Conditional routing** to regenerate code by reflecting on the errors if any OR stop generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uyAVd79ZNkzq",
      "metadata": {
        "id": "uyAVd79ZNkzq"
      },
      "source": [
        "### Create Agent State Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "kkLFqqP7R-f8",
      "metadata": {
        "id": "kkLFqqP7R-f8"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List\n",
        "from langgraph.graph.message import AnyMessage, add_messages\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "class CodeGenState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        error_flag : Binary flag for control flow to indicate whether test error was tripped\n",
        "        messages : With user question, error messages, reasoning\n",
        "        code_solution : Code solution\n",
        "        attempts : Number of tries\n",
        "    \"\"\"\n",
        "    error_flag: str\n",
        "    messages: Annotated[List[AnyMessage], add_messages]\n",
        "    code_solution: str\n",
        "    attempts: int"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nItiFjSyR-f8",
      "metadata": {
        "id": "nItiFjSyR-f8"
      },
      "source": [
        "### Node 1: Generate Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9PysfORUR-f8",
      "metadata": {
        "id": "9PysfORUR-f8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_code(state: CodeGenState) -> CodeGenState:\n",
        "    \"\"\"Generate code solution from LLM, structured as prefix/imports/code.\"\"\"\n",
        "    print(\"--- GENERATING CODE SOLUTION ---\")\n",
        "    msgs = state[\"messages\"]\n",
        "    attempts_so_far = state[\"attempts\"]\n",
        "\n",
        "    # Call code_generation_chain\n",
        "    code_soln = code_generator.invoke(CODE_GEN_SYS_PROMPT + msgs)\n",
        "\n",
        "    # We'll record the chain's answer as a new assistant message in conversation.\n",
        "    new_msg_content = (f\"Here is my solution attempt:\\n\\nDescription: {code_soln.prefix}\\n\\n\"\n",
        "                       f\"Imports: {code_soln.imports}\\n\\n\"\n",
        "                       f\"Code:\\n{code_soln.code}\")\n",
        "\n",
        "    msgs.append((\"assistant\", new_msg_content))\n",
        "    attempts_so_far += 1\n",
        "\n",
        "    return {\n",
        "        \"messages\": msgs,\n",
        "        \"code_solution\": code_soln,\n",
        "        \"attempts\": attempts_so_far\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VlcJl7KfR-f9",
      "metadata": {
        "id": "VlcJl7KfR-f9"
      },
      "source": [
        "### Node 2: Check Code\n",
        "\n",
        "We try to `exec` the imports, then `exec` the code. If errors occur, we pass them back to the conversation. Otherwise, success."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bogJImiLiRrs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bogJImiLiRrs",
        "outputId": "f05b71bc-2757-4bb4-8639-cfef0d4932a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: 75\n"
          ]
        }
      ],
      "source": [
        "# sample code of how exec works\n",
        "user_code = \"\"\"\n",
        "x = 5\n",
        "y = 15\n",
        "print('Result:', x * y)\n",
        "\"\"\"\n",
        "exec(user_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "UZIEvj5JR-f9",
      "metadata": {
        "id": "UZIEvj5JR-f9"
      },
      "outputs": [],
      "source": [
        "def check_code_execution(state: CodeGenState) -> CodeGenState:\n",
        "    print(\"--- CHECKING CODE EXECUTION ---\")\n",
        "    msgs = state[\"messages\"]\n",
        "    code_soln = state[\"code_solution\"]\n",
        "    imports_str = code_soln.imports\n",
        "    code_str = code_soln.code\n",
        "    attempts = state[\"attempts\"]\n",
        "\n",
        "    # Attempt to import:\n",
        "    try:\n",
        "        exec(imports_str)\n",
        "    except Exception as e:\n",
        "        # Import failed\n",
        "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
        "        error_msg = f\"\"\"Import test failed!\n",
        "                        Here is the exception trace details:\n",
        "                        {e}.\n",
        "\n",
        "                        Please fix the import section.\"\"\"\n",
        "\n",
        "        msgs.append((\"user\", error_msg))\n",
        "        return {\n",
        "            \"code_solution\": code_soln,\n",
        "            \"attempts\": attempts,\n",
        "            \"messages\": msgs,\n",
        "            \"error_flag\": \"yes\"\n",
        "        }\n",
        "\n",
        "    # Attempt to run code:\n",
        "    try:\n",
        "        scope = {}\n",
        "        exec(f\"{imports_str}\\n{code_str}\", scope)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
        "        error_msg =  f\"\"\"Your code solution failed the code execution test!\n",
        "                            Here is the exception trace details:\n",
        "                            {e}\n",
        "\n",
        "                            Reflect on this error and your prior attempt to solve the problem.\n",
        "\n",
        "                            (1) State what you think went wrong with the prior solution\n",
        "                            (2) try to solve this problem again.\n",
        "\n",
        "                            Return the FULL SOLUTION.\n",
        "\n",
        "                            Use the code tool to structure the output with a prefix, imports, and code block.\"\"\"\n",
        "\n",
        "        msgs.append((\"user\", error_msg))\n",
        "        return {\n",
        "            \"code_solution\": code_soln,\n",
        "            \"attempts\": attempts,\n",
        "            \"messages\": msgs,\n",
        "            \"error_flag\": \"yes\"\n",
        "        }\n",
        "\n",
        "    # If no errors:\n",
        "    print(\"--- NO ERRORS FOUND ---\")\n",
        "    return {\n",
        "            \"code_solution\": code_soln,\n",
        "            \"attempts\": attempts,\n",
        "            \"messages\": msgs,\n",
        "            \"error_flag\": \"no\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mYDXdIUuR-f9",
      "metadata": {
        "id": "mYDXdIUuR-f9"
      },
      "source": [
        "### Conditional Routing to Decide Next Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "BCHA7wMfR-f9",
      "metadata": {
        "id": "BCHA7wMfR-f9"
      },
      "outputs": [],
      "source": [
        "MAX_ATTEMPTS = 3\n",
        "\n",
        "def decide_next(state: CodeGenState) -> str:\n",
        "    \"\"\"If error or attempts < MAX_ATTEMPTS => go generate. Else end.\"\"\"\n",
        "    err = state[\"error_flag\"]\n",
        "    attempts = state[\"attempts\"]\n",
        "    if err == \"no\" or attempts >= MAX_ATTEMPTS:\n",
        "        print(\"--- DECISION: FINISH ---\")\n",
        "        return \"__end__\"\n",
        "    else:\n",
        "        print(\"--- DECISION: RETRY ---\")\n",
        "        return \"generate_code\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cx1zepdwR-f9",
      "metadata": {
        "id": "Cx1zepdwR-f9"
      },
      "source": [
        "## Build the Reflection Agentic Graph\n",
        "\n",
        "We'll define the nodes and edges in LangGraph, then run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "-QTi1pcVR-f-",
      "metadata": {
        "id": "-QTi1pcVR-f-"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "graph = StateGraph(CodeGenState)\n",
        "\n",
        "# Add nodes:\n",
        "graph.add_node(\"generate_code\", generate_code)\n",
        "graph.add_node(\"check_code\", check_code_execution)\n",
        "\n",
        "# Edges:\n",
        "graph.set_entry_point(\"generate_code\")\n",
        "graph.add_edge(\"generate_code\", \"check_code\")\n",
        "graph.add_conditional_edges(\n",
        "    \"check_code\",\n",
        "    decide_next,\n",
        "    [END, \"generate_code\"]\n",
        ")\n",
        "\n",
        "coder_agent = graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "GKqe7NjadtfJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "GKqe7NjadtfJ",
        "outputId": "f5228d79-478c-4ef0-9b24-102344812659"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "display(Image(coder_agent.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yKO8GSxiR-f-",
      "metadata": {
        "id": "yKO8GSxiR-f-"
      },
      "source": [
        "## Run and Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9WJ6dD3Eepen",
      "metadata": {
        "id": "9WJ6dD3Eepen"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def call_reflection_coding_agent(agent, prompt, verbose=False):\n",
        "    events = agent.stream(\n",
        "        {\"messages\": [HumanMessage(content=prompt)], \"attempts\": 0},\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    print('Running Agent. Please wait...')\n",
        "    for event in events:\n",
        "        if verbose:\n",
        "            event[\"messages\"][-1].pretty_print()\n",
        "\n",
        "    print('\\n\\nFinal Solution:')\n",
        "    print(\"\\nDescription:\\n\" + event[\"code_solution\"].prefix +\n",
        "          \"\\nCode:\\n\"+event[\"code_solution\"].imports + '\\n\\n' + event[\"code_solution\"].code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "XtkvnDbefDsN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtkvnDbefDsN",
        "outputId": "36ea37b6-301e-421f-da20-1c14431d32fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "write some code to demonstrate how to do a pivot table in pandas\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: Below is a minimal, self‑contained example that shows how to create a pivot table in pandas. It builds a small DataFrame, uses `pivot_table` to aggregate data, and prints the result. You can copy‑paste the entire snippet into a Python environment and run it directly.\n",
            "\n",
            "Imports: import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "Code:\n",
            "# Create a sample DataFrame\n",
            "np.random.seed(0)\n",
            "\n",
            "df = pd.DataFrame({\n",
            "    'Store': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n",
            "    'Product': ['Apple', 'Banana', 'Apple', 'Banana', 'Apple', 'Banana', 'Cherry'],\n",
            "    'Sales': [120, 80, 150, 90, 200, 110, 70],\n",
            "    'Quantity': [10, 5, 12, 6, 20, 11, 7]\n",
            "})\n",
            "\n",
            "print(\"Original DataFrame:\\n\", df)\n",
            "\n",
            "# Pivot table: total sales and average quantity per store and product\n",
            "pivot = pd.pivot_table(\n",
            "    df,\n",
            "    values=['Sales', 'Quantity'],\n",
            "    index='Store',\n",
            "    columns='Product',\n",
            "    aggfunc={'Sales': 'sum', 'Quantity': 'mean'},\n",
            "    fill_value=0\n",
            ")\n",
            "\n",
            "print(\"\\nPivot table (Sales sum, Quantity mean):\\n\", pivot)\n",
            "\n",
            "# If you want a flat table (no multi‑index columns), you can reset the column names\n",
            "pivot_flat = pivot.copy()\n",
            "pivot_flat.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_flat.columns]\n",
            "print(\"\\nFlat pivot table:\\n\", pivot_flat)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: RETRY ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'pandas'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: This code demonstrates how to create a pivot table in pandas. It includes a safety‑net that will install pandas automatically if it is not already available in the environment.\n",
            "\n",
            "Imports: import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "Code:\n",
            "# ---------------------------------------------------------------------------\n",
            "# 1️⃣  Ensure pandas is available – install it if necessary\n",
            "# ---------------------------------------------------------------------------\n",
            "try:\n",
            "    import pandas as pd\n",
            "except ImportError:  # pragma: no cover\n",
            "    import subprocess, sys\n",
            "    print(\"pandas not found – installing via pip…\")\n",
            "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas'])\n",
            "    import pandas as pd\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 2️⃣  Create a sample DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "np.random.seed(0)\n",
            "\n",
            "df = pd.DataFrame({\n",
            "    'Store': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n",
            "    'Product': ['Apple', 'Banana', 'Apple', 'Banana', 'Apple', 'Banana', 'Cherry'],\n",
            "    'Sales': [120, 80, 150, 90, 200, 110, 70],\n",
            "    'Quantity': [10, 5, 12, 6, 20, 11, 7]\n",
            "})\n",
            "\n",
            "print(\"Original DataFrame:\\n\", df)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 3️⃣  Build a pivot table\n",
            "# ---------------------------------------------------------------------------\n",
            "#   • index  : rows – each store\n",
            "#   • columns: each product\n",
            "#   • values : two metrics – total sales and average quantity\n",
            "#   • aggfunc: sum for Sales, mean for Quantity\n",
            "#   • fill_value: 0 for missing combinations\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot = pd.pivot_table(\n",
            "    df,\n",
            "    values=['Sales', 'Quantity'],\n",
            "    index='Store',\n",
            "    columns='Product',\n",
            "    aggfunc={'Sales': 'sum', 'Quantity': 'mean'},\n",
            "    fill_value=0\n",
            ")\n",
            "\n",
            "print(\"\\nPivot table (Sales sum, Quantity mean):\\n\", pivot)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 4️⃣  Optional – flatten the multi‑index columns for a tidy DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot_flat = pivot.copy()\n",
            "pivot_flat.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_flat.columns]\n",
            "print(\"\\nFlat pivot table:\\n\", pivot_flat)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: RETRY ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'pandas'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: This script demonstrates how to create a pivot table in pandas, with a fallback that installs pandas if it is missing.\n",
            "\n",
            "Imports: import subprocess, sys\n",
            "\n",
            "Code:\n",
            "# ---------------------------------------------------------------------------\n",
            "# 1️⃣  Ensure pandas is available – install it if necessary\n",
            "# ---------------------------------------------------------------------------\n",
            "try:\n",
            "    import pandas as pd\n",
            "except ImportError:  # pragma: no cover\n",
            "    print(\"pandas not found – installing via pip…\")\n",
            "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas'])\n",
            "    import pandas as pd\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 2️⃣  Create a sample DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "import numpy as np\n",
            "np.random.seed(0)\n",
            "\n",
            "df = pd.DataFrame({\n",
            "    'Store': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n",
            "    'Product': ['Apple', 'Banana', 'Apple', 'Banana', 'Apple', 'Banana', 'Cherry'],\n",
            "    'Sales': [120, 80, 150, 90, 200, 110, 70],\n",
            "    'Quantity': [10, 5, 12, 6, 20, 11, 7]\n",
            "})\n",
            "\n",
            "print(\"Original DataFrame:\\n\", df)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 3️⃣  Build a pivot table\n",
            "# ---------------------------------------------------------------------------\n",
            "#   • index  : rows – each store\n",
            "#   • columns: each product\n",
            "#   • values : two metrics – total sales and average quantity\n",
            "#   • aggfunc: sum for Sales, mean for Quantity\n",
            "#   • fill_value: 0 for missing combinations\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot = pd.pivot_table(\n",
            "    df,\n",
            "    values=['Sales', 'Quantity'],\n",
            "    index='Store',\n",
            "    columns='Product',\n",
            "    aggfunc={'Sales': 'sum', 'Quantity': 'mean'},\n",
            "    fill_value=0\n",
            ")\n",
            "\n",
            "print(\"\\nPivot table (Sales sum, Quantity mean):\\n\", pivot)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 4️⃣  Optional – flatten the multi‑index columns for a tidy DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot_flat = pivot.copy()\n",
            "pivot_flat.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_flat.columns]\n",
            "print(\"\\nFlat pivot table:\\n\", pivot_flat)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "pandas not found – installing via pip…\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /home/wesee/miniconda3/envs/analytics_vidhya/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/wesee/miniconda3/envs/analytics_vidhya/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/wesee/miniconda3/envs/analytics_vidhya/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/wesee/miniconda3/envs/analytics_vidhya/lib/python3.10/site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/wesee/miniconda3/envs/analytics_vidhya/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "Successfully installed pandas-2.3.3\n",
            "Original DataFrame:\n",
            "   Store Product  Sales  Quantity\n",
            "0     A   Apple    120        10\n",
            "1     A  Banana     80         5\n",
            "2     B   Apple    150        12\n",
            "3     B  Banana     90         6\n",
            "4     C   Apple    200        20\n",
            "5     C  Banana    110        11\n",
            "6     C  Cherry     70         7\n",
            "\n",
            "Pivot table (Sales sum, Quantity mean):\n",
            "         Quantity               Sales              \n",
            "Product    Apple Banana Cherry Apple Banana Cherry\n",
            "Store                                             \n",
            "A           10.0    5.0    0.0   120     80      0\n",
            "B           12.0    6.0    0.0   150     90      0\n",
            "C           20.0   11.0    7.0   200    110     70\n",
            "\n",
            "Flat pivot table:\n",
            "        Apple_Quantity  Banana_Quantity  Cherry_Quantity  Apple_Sales  \\\n",
            "Store                                                                  \n",
            "A                10.0              5.0              0.0          120   \n",
            "B                12.0              6.0              0.0          150   \n",
            "C                20.0             11.0              7.0          200   \n",
            "\n",
            "       Banana_Sales  Cherry_Sales  \n",
            "Store                              \n",
            "A                80             0  \n",
            "B                90             0  \n",
            "C               110            70  \n",
            "--- NO ERRORS FOUND ---\n",
            "--- DECISION: FINISH ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: This script demonstrates how to create a pivot table in pandas, with a fallback that installs pandas if it is missing.\n",
            "\n",
            "Imports: import subprocess, sys\n",
            "\n",
            "Code:\n",
            "# ---------------------------------------------------------------------------\n",
            "# 1️⃣  Ensure pandas is available – install it if necessary\n",
            "# ---------------------------------------------------------------------------\n",
            "try:\n",
            "    import pandas as pd\n",
            "except ImportError:  # pragma: no cover\n",
            "    print(\"pandas not found – installing via pip…\")\n",
            "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas'])\n",
            "    import pandas as pd\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 2️⃣  Create a sample DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "import numpy as np\n",
            "np.random.seed(0)\n",
            "\n",
            "df = pd.DataFrame({\n",
            "    'Store': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n",
            "    'Product': ['Apple', 'Banana', 'Apple', 'Banana', 'Apple', 'Banana', 'Cherry'],\n",
            "    'Sales': [120, 80, 150, 90, 200, 110, 70],\n",
            "    'Quantity': [10, 5, 12, 6, 20, 11, 7]\n",
            "})\n",
            "\n",
            "print(\"Original DataFrame:\\n\", df)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 3️⃣  Build a pivot table\n",
            "# ---------------------------------------------------------------------------\n",
            "#   • index  : rows – each store\n",
            "#   • columns: each product\n",
            "#   • values : two metrics – total sales and average quantity\n",
            "#   • aggfunc: sum for Sales, mean for Quantity\n",
            "#   • fill_value: 0 for missing combinations\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot = pd.pivot_table(\n",
            "    df,\n",
            "    values=['Sales', 'Quantity'],\n",
            "    index='Store',\n",
            "    columns='Product',\n",
            "    aggfunc={'Sales': 'sum', 'Quantity': 'mean'},\n",
            "    fill_value=0\n",
            ")\n",
            "\n",
            "print(\"\\nPivot table (Sales sum, Quantity mean):\\n\", pivot)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 4️⃣  Optional – flatten the multi‑index columns for a tidy DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot_flat = pivot.copy()\n",
            "pivot_flat.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_flat.columns]\n",
            "print(\"\\nFlat pivot table:\\n\", pivot_flat)\n",
            "\n",
            "\n",
            "Final Solution:\n",
            "\n",
            "Description:\n",
            "This script demonstrates how to create a pivot table in pandas, with a fallback that installs pandas if it is missing.\n",
            "Code:\n",
            "import subprocess, sys\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 1️⃣  Ensure pandas is available – install it if necessary\n",
            "# ---------------------------------------------------------------------------\n",
            "try:\n",
            "    import pandas as pd\n",
            "except ImportError:  # pragma: no cover\n",
            "    print(\"pandas not found – installing via pip…\")\n",
            "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pandas'])\n",
            "    import pandas as pd\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 2️⃣  Create a sample DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "import numpy as np\n",
            "np.random.seed(0)\n",
            "\n",
            "df = pd.DataFrame({\n",
            "    'Store': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n",
            "    'Product': ['Apple', 'Banana', 'Apple', 'Banana', 'Apple', 'Banana', 'Cherry'],\n",
            "    'Sales': [120, 80, 150, 90, 200, 110, 70],\n",
            "    'Quantity': [10, 5, 12, 6, 20, 11, 7]\n",
            "})\n",
            "\n",
            "print(\"Original DataFrame:\\n\", df)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 3️⃣  Build a pivot table\n",
            "# ---------------------------------------------------------------------------\n",
            "#   • index  : rows – each store\n",
            "#   • columns: each product\n",
            "#   • values : two metrics – total sales and average quantity\n",
            "#   • aggfunc: sum for Sales, mean for Quantity\n",
            "#   • fill_value: 0 for missing combinations\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot = pd.pivot_table(\n",
            "    df,\n",
            "    values=['Sales', 'Quantity'],\n",
            "    index='Store',\n",
            "    columns='Product',\n",
            "    aggfunc={'Sales': 'sum', 'Quantity': 'mean'},\n",
            "    fill_value=0\n",
            ")\n",
            "\n",
            "print(\"\\nPivot table (Sales sum, Quantity mean):\\n\", pivot)\n",
            "\n",
            "# ---------------------------------------------------------------------------\n",
            "# 4️⃣  Optional – flatten the multi‑index columns for a tidy DataFrame\n",
            "# ---------------------------------------------------------------------------\n",
            "pivot_flat = pivot.copy()\n",
            "pivot_flat.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_flat.columns]\n",
            "print(\"\\nFlat pivot table:\\n\", pivot_flat)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"write some code to demonstrate how to do a pivot table in pandas\"\n",
        "call_reflection_coding_agent(coder_agent, prompt, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "oChd321sfSuE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oChd321sfSuE",
        "outputId": "d4975f3d-8888-41b9-beeb-97e2a708ef75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "write some code how to extract code from .ipynb notebook and make it .py without any error.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: This script reads a Jupyter Notebook (.ipynb) file, extracts all code cells, and writes them to a plain Python (.py) file. It uses the `nbformat` library (part of the Jupyter ecosystem) to parse the notebook JSON structure safely. The code includes basic error handling and a small demo that can be run directly from the command line.\n",
            "\n",
            "**Prerequisites**: `pip install nbformat` if you don’t already have it.\n",
            "\n",
            "**Usage**:\n",
            "```bash\n",
            "python extract_notebook.py path/to/notebook.ipynb path/to/output.py\n",
            "```\n",
            "\n",
            "If you run the script without arguments it will print a short help message.\n",
            "\n",
            "---\n",
            "\n",
            "**Imports**\n",
            "\n",
            "\n",
            "Imports: import sys\n",
            "import os\n",
            "import nbformat\n",
            "from nbformat import NotebookNode\n",
            "\n",
            "\n",
            "\n",
            "Code:\n",
            "def extract_notebook_to_py(notebook_path: str, output_path: str) -> None:\n",
            "    \"\"\"Extracts all code cells from a Jupyter notebook and writes them to a .py file.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    notebook_path: str\n",
            "        Path to the source .ipynb file.\n",
            "    output_path: str\n",
            "        Path where the resulting .py file will be written.\n",
            "    \"\"\"\n",
            "    # Validate input file\n",
            "    if not os.path.isfile(notebook_path):\n",
            "        raise FileNotFoundError(f\"Notebook file not found: {notebook_path}\")\n",
            "\n",
            "    # Load the notebook using nbformat\n",
            "    try:\n",
            "        nb: NotebookNode = nbformat.read(notebook_path, as_version=4)\n",
            "    except Exception as e:\n",
            "        raise ValueError(f\"Failed to read notebook '{notebook_path}': {e}\")\n",
            "\n",
            "    # Collect code from all cells of type 'code'\n",
            "    code_lines = []\n",
            "    for cell in nb.cells:\n",
            "        if cell.cell_type == 'code':\n",
            "            # Preserve the original code exactly as it appears\n",
            "            code_lines.append(cell.source)\n",
            "            # Add a newline to separate cells\n",
            "            code_lines.append(\"\\n\")\n",
            "\n",
            "    # Join all lines into a single string\n",
            "    python_code = \"\".join(code_lines)\n",
            "\n",
            "    # Write to the output .py file\n",
            "    try:\n",
            "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
            "            f.write(python_code)\n",
            "    except Exception as e:\n",
            "        raise IOError(f\"Failed to write to '{output_path}': {e}\")\n",
            "\n",
            "    print(f\"Successfully extracted {len(code_lines)//2} code cells to '{output_path}'.\")\n",
            "\n",
            "\n",
            "# Demo / command‑line interface\n",
            "if __name__ == \"__main__\":\n",
            "    if len(sys.argv) != 3:\n",
            "        print(\"Usage: python extract_notebook.py <notebook.ipynb> <output.py>\")\n",
            "        sys.exit(1)\n",
            "\n",
            "    nb_path = sys.argv[1]\n",
            "    out_path = sys.argv[2]\n",
            "\n",
            "    try:\n",
            "        extract_notebook_to_py(nb_path, out_path)\n",
            "    except Exception as exc:\n",
            "        print(f\"Error: {exc}\")\n",
            "        sys.exit(1)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "--- NO ERRORS FOUND ---\n",
            "--- DECISION: FINISH ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: This script reads a Jupyter Notebook (.ipynb) file, extracts all code cells, and writes them to a plain Python (.py) file. It uses the `nbformat` library (part of the Jupyter ecosystem) to parse the notebook JSON structure safely. The code includes basic error handling and a small demo that can be run directly from the command line.\n",
            "\n",
            "**Prerequisites**: `pip install nbformat` if you don’t already have it.\n",
            "\n",
            "**Usage**:\n",
            "```bash\n",
            "python extract_notebook.py path/to/notebook.ipynb path/to/output.py\n",
            "```\n",
            "\n",
            "If you run the script without arguments it will print a short help message.\n",
            "\n",
            "---\n",
            "\n",
            "**Imports**\n",
            "\n",
            "\n",
            "Imports: import sys\n",
            "import os\n",
            "import nbformat\n",
            "from nbformat import NotebookNode\n",
            "\n",
            "\n",
            "\n",
            "Code:\n",
            "def extract_notebook_to_py(notebook_path: str, output_path: str) -> None:\n",
            "    \"\"\"Extracts all code cells from a Jupyter notebook and writes them to a .py file.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    notebook_path: str\n",
            "        Path to the source .ipynb file.\n",
            "    output_path: str\n",
            "        Path where the resulting .py file will be written.\n",
            "    \"\"\"\n",
            "    # Validate input file\n",
            "    if not os.path.isfile(notebook_path):\n",
            "        raise FileNotFoundError(f\"Notebook file not found: {notebook_path}\")\n",
            "\n",
            "    # Load the notebook using nbformat\n",
            "    try:\n",
            "        nb: NotebookNode = nbformat.read(notebook_path, as_version=4)\n",
            "    except Exception as e:\n",
            "        raise ValueError(f\"Failed to read notebook '{notebook_path}': {e}\")\n",
            "\n",
            "    # Collect code from all cells of type 'code'\n",
            "    code_lines = []\n",
            "    for cell in nb.cells:\n",
            "        if cell.cell_type == 'code':\n",
            "            # Preserve the original code exactly as it appears\n",
            "            code_lines.append(cell.source)\n",
            "            # Add a newline to separate cells\n",
            "            code_lines.append(\"\\n\")\n",
            "\n",
            "    # Join all lines into a single string\n",
            "    python_code = \"\".join(code_lines)\n",
            "\n",
            "    # Write to the output .py file\n",
            "    try:\n",
            "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
            "            f.write(python_code)\n",
            "    except Exception as e:\n",
            "        raise IOError(f\"Failed to write to '{output_path}': {e}\")\n",
            "\n",
            "    print(f\"Successfully extracted {len(code_lines)//2} code cells to '{output_path}'.\")\n",
            "\n",
            "\n",
            "# Demo / command‑line interface\n",
            "if __name__ == \"__main__\":\n",
            "    if len(sys.argv) != 3:\n",
            "        print(\"Usage: python extract_notebook.py <notebook.ipynb> <output.py>\")\n",
            "        sys.exit(1)\n",
            "\n",
            "    nb_path = sys.argv[1]\n",
            "    out_path = sys.argv[2]\n",
            "\n",
            "    try:\n",
            "        extract_notebook_to_py(nb_path, out_path)\n",
            "    except Exception as exc:\n",
            "        print(f\"Error: {exc}\")\n",
            "        sys.exit(1)\n",
            "\n",
            "\n",
            "Final Solution:\n",
            "\n",
            "Description:\n",
            "This script reads a Jupyter Notebook (.ipynb) file, extracts all code cells, and writes them to a plain Python (.py) file. It uses the `nbformat` library (part of the Jupyter ecosystem) to parse the notebook JSON structure safely. The code includes basic error handling and a small demo that can be run directly from the command line.\n",
            "\n",
            "**Prerequisites**: `pip install nbformat` if you don’t already have it.\n",
            "\n",
            "**Usage**:\n",
            "```bash\n",
            "python extract_notebook.py path/to/notebook.ipynb path/to/output.py\n",
            "```\n",
            "\n",
            "If you run the script without arguments it will print a short help message.\n",
            "\n",
            "---\n",
            "\n",
            "**Imports**\n",
            "\n",
            "Code:\n",
            "import sys\n",
            "import os\n",
            "import nbformat\n",
            "from nbformat import NotebookNode\n",
            "\n",
            "\n",
            "\n",
            "def extract_notebook_to_py(notebook_path: str, output_path: str) -> None:\n",
            "    \"\"\"Extracts all code cells from a Jupyter notebook and writes them to a .py file.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    notebook_path: str\n",
            "        Path to the source .ipynb file.\n",
            "    output_path: str\n",
            "        Path where the resulting .py file will be written.\n",
            "    \"\"\"\n",
            "    # Validate input file\n",
            "    if not os.path.isfile(notebook_path):\n",
            "        raise FileNotFoundError(f\"Notebook file not found: {notebook_path}\")\n",
            "\n",
            "    # Load the notebook using nbformat\n",
            "    try:\n",
            "        nb: NotebookNode = nbformat.read(notebook_path, as_version=4)\n",
            "    except Exception as e:\n",
            "        raise ValueError(f\"Failed to read notebook '{notebook_path}': {e}\")\n",
            "\n",
            "    # Collect code from all cells of type 'code'\n",
            "    code_lines = []\n",
            "    for cell in nb.cells:\n",
            "        if cell.cell_type == 'code':\n",
            "            # Preserve the original code exactly as it appears\n",
            "            code_lines.append(cell.source)\n",
            "            # Add a newline to separate cells\n",
            "            code_lines.append(\"\\n\")\n",
            "\n",
            "    # Join all lines into a single string\n",
            "    python_code = \"\".join(code_lines)\n",
            "\n",
            "    # Write to the output .py file\n",
            "    try:\n",
            "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
            "            f.write(python_code)\n",
            "    except Exception as e:\n",
            "        raise IOError(f\"Failed to write to '{output_path}': {e}\")\n",
            "\n",
            "    print(f\"Successfully extracted {len(code_lines)//2} code cells to '{output_path}'.\")\n",
            "\n",
            "\n",
            "# Demo / command‑line interface\n",
            "if __name__ == \"__main__\":\n",
            "    if len(sys.argv) != 3:\n",
            "        print(\"Usage: python extract_notebook.py <notebook.ipynb> <output.py>\")\n",
            "        sys.exit(1)\n",
            "\n",
            "    nb_path = sys.argv[1]\n",
            "    out_path = sys.argv[2]\n",
            "\n",
            "    try:\n",
            "        extract_notebook_to_py(nb_path, out_path)\n",
            "    except Exception as exc:\n",
            "        print(f\"Error: {exc}\")\n",
            "        sys.exit(1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"write some code how to extract code from .ipynb notebook and make it .py without any error.\"\n",
        "call_reflection_coding_agent(coder_agent, prompt, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "x87LQC39fw1U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x87LQC39fw1U",
        "outputId": "aeec2be7-f24a-4530-c501-541771b196aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Give me working code to get data from Twitter using API\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: To access data from Twitter using their API, you need to use the Tweepy library, which is a popular Python library for accessing the Twitter API. First, you need to create a Twitter Developer account and create an app to get your API keys and tokens. Once you have these credentials, you can use Tweepy to authenticate and fetch data from Twitter.\n",
            "\n",
            "Imports: import tweepy\n",
            "\n",
            "Code:\n",
            "# Replace these with your own credentials\n",
            "API_KEY = 'your_api_key'\n",
            "API_SECRET_KEY = 'your_api_secret_key'\n",
            "ACCESS_TOKEN = 'your_access_token'\n",
            "ACCESS_TOKEN_SECRET = 'your_access_token_secret'\n",
            "\n",
            "# Authenticate to Twitter\n",
            "auth = tweepy.OAuth1UserHandler(API_KEY, API_SECRET_KEY, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
            "\n",
            "# Create API object\n",
            "api = tweepy.API(auth)\n",
            "\n",
            "# Get the User object for twitter...\n",
            "user = api.get_user(screen_name='twitter')\n",
            "\n",
            "print('User details:')\n",
            "print(user.name)\n",
            "print(user.description)\n",
            "print(user.location)\n",
            "\n",
            "print('Last 5 Followers:')\n",
            "for follower in user.followers(count=5):\n",
            "    print(follower.name)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: RETRY ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'tweepy'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: To access data from Twitter using their API, you need to use the Tweepy library, which is a popular Python library for accessing the Twitter API. First, you need to create a Twitter Developer account and create an app to get your API keys and tokens. Once you have these credentials, you can use Tweepy to authenticate and fetch data from Twitter. Make sure to install the Tweepy library using pip if it's not already installed.\n",
            "\n",
            "Imports: !pip install tweepy\n",
            "import tweepy\n",
            "\n",
            "Code:\n",
            "# Replace these with your own credentials\n",
            "API_KEY = 'your_api_key'\n",
            "API_SECRET_KEY = 'your_api_secret_key'\n",
            "ACCESS_TOKEN = 'your_access_token'\n",
            "ACCESS_TOKEN_SECRET = 'your_access_token_secret'\n",
            "\n",
            "# Authenticate to Twitter\n",
            "auth = tweepy.OAuth1UserHandler(API_KEY, API_SECRET_KEY, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
            "\n",
            "# Create API object\n",
            "api = tweepy.API(auth)\n",
            "\n",
            "# Get the User object for twitter...\n",
            "user = api.get_user(screen_name='twitter')\n",
            "\n",
            "print('User details:')\n",
            "print(user.name)\n",
            "print(user.description)\n",
            "print(user.location)\n",
            "\n",
            "print('Last 5 Followers:')\n",
            "for follower in user.followers(count=5):\n",
            "    print(follower.name)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: RETRY ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        invalid syntax (<string>, line 1).\n",
            "\n",
            "                        Please fix the import section.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: To access data from Twitter using their API, you need to use the Tweepy library, which is a popular Python library for accessing the Twitter API. First, you need to create a Twitter Developer account and create an app to get your API keys and tokens. Once you have these credentials, you can use Tweepy to authenticate and fetch data from Twitter. Make sure to install the Tweepy library using pip if it's not already installed.\n",
            "\n",
            "Imports: import tweepy\n",
            "\n",
            "Code:\n",
            "# Install tweepy using pip if not already installed\n",
            "# !pip install tweepy\n",
            "\n",
            "# Replace these with your own credentials\n",
            "API_KEY = 'your_api_key'\n",
            "API_SECRET_KEY = 'your_api_secret_key'\n",
            "ACCESS_TOKEN = 'your_access_token'\n",
            "ACCESS_TOKEN_SECRET = 'your_access_token_secret'\n",
            "\n",
            "# Authenticate to Twitter\n",
            "auth = tweepy.OAuth1UserHandler(API_KEY, API_SECRET_KEY, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
            "\n",
            "# Create API object\n",
            "api = tweepy.API(auth)\n",
            "\n",
            "# Get the User object for twitter...\n",
            "user = api.get_user(screen_name='twitter')\n",
            "\n",
            "print('User details:')\n",
            "print(user.name)\n",
            "print(user.description)\n",
            "print(user.location)\n",
            "\n",
            "print('Last 5 Followers:')\n",
            "for follower in user.followers(count=5):\n",
            "    print(follower.name)\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: FINISH ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'tweepy'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "\n",
            "\n",
            "Final Solution:\n",
            "\n",
            "Description:\n",
            "To access data from Twitter using their API, you need to use the Tweepy library, which is a popular Python library for accessing the Twitter API. First, you need to create a Twitter Developer account and create an app to get your API keys and tokens. Once you have these credentials, you can use Tweepy to authenticate and fetch data from Twitter. Make sure to install the Tweepy library using pip if it's not already installed.\n",
            "Code:\n",
            "import tweepy\n",
            "\n",
            "# Install tweepy using pip if not already installed\n",
            "# !pip install tweepy\n",
            "\n",
            "# Replace these with your own credentials\n",
            "API_KEY = 'your_api_key'\n",
            "API_SECRET_KEY = 'your_api_secret_key'\n",
            "ACCESS_TOKEN = 'your_access_token'\n",
            "ACCESS_TOKEN_SECRET = 'your_access_token_secret'\n",
            "\n",
            "# Authenticate to Twitter\n",
            "auth = tweepy.OAuth1UserHandler(API_KEY, API_SECRET_KEY, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
            "\n",
            "# Create API object\n",
            "api = tweepy.API(auth)\n",
            "\n",
            "# Get the User object for twitter...\n",
            "user = api.get_user(screen_name='twitter')\n",
            "\n",
            "print('User details:')\n",
            "print(user.name)\n",
            "print(user.description)\n",
            "print(user.location)\n",
            "\n",
            "print('Last 5 Followers:')\n",
            "for follower in user.followers(count=5):\n",
            "    print(follower.name)\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Give me working code to get data from Twitter using API\"\"\"\n",
        "call_reflection_coding_agent(coder_agent, prompt, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "kPoCwfT5jXpr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7a0b493a8f01472c9a61c640e952f0f7",
            "83ae4bb485104e14abcc6f7c7b60ba3d",
            "64e47da0c8aa44af835aa0e30150294c",
            "ee500f570f304160acb715c6b00cd236",
            "bb7d8e1cbb824e73b89ff73a24768cae",
            "eeaf0ac3d2bc43c58e78036416217285",
            "2c96baf1be004193bd98b93b23deef04",
            "0b82beadca9f48d88769ab96540d09e9",
            "e71e12e226e14fa5a63f8dfbe696aa94",
            "fef52b8172f649de919d8f3d68c8cee1",
            "045a5cb3cb4347ccad78fe28e37cb56c",
            "eca8a9ab2ccc429e888a369522fa14f3",
            "588b121da6454b3b8c5d9a71966d01bd",
            "511d77ef6ed043dc8a7a44cf7f610115",
            "2304b2fbdb574ce28ddb3aa0857b125b",
            "a1c019623ce542399533684a80090771",
            "2f0c0a41d0bc4608860f314cde2dadf0",
            "a88e73b9f2af4c58bc44aa1cc8a414fa",
            "869aaf1c022a48e79209719e9998c499",
            "540d85ade4bc4a5693cfce545bb3c061",
            "61a70cdc20a4410c922ace16692206da",
            "f132ee49c4a040f4891c525aced7a692",
            "3f317244ce484f568df200ea3d401346",
            "4c08fd0039f540f5848a077014b410d7",
            "6be0a60eebad4b759c4dd9ccbcacc3b8",
            "174269ed4b334850b834ad5fc8835ecc",
            "c54f1c082ee24e01a03f27296ad1f926",
            "47e72fae6e8c4f5f9f5508321a87e0ca",
            "be7521b633b940fda794e388fc859668",
            "a7808e62088d4878978574c8dcfd9c65",
            "b7838347ac8b4fc38ff1c177c7b29c16",
            "9dfc8fadcba54896a7fbb2237e9fd74d",
            "d2e192c6b21b46e6a8788f4a4b5ba92b",
            "a98ff8e7e03149b8ba8a4df45d64c0b8",
            "5c8d93b2c0044cda95f1f3b8b6f4ab9b",
            "dc95db6884734d9fa24106b23842252f",
            "c303b39b68e244148b4039280d393327",
            "aee08eb6ee0245f3bc052705d901f1e1",
            "5cb53b28433c4e32875fd93e216fc61d",
            "b3edcb443c8a4f84b97f1c091a1ba7af",
            "4358b3ec606940428d00114d795bc982",
            "d37ad6ac566c4df79b8b70fc3cbca94f",
            "4ef519e3baa449a7952bbb919ac825d6",
            "470408cd284943998d825ad75f77e876"
          ]
        },
        "id": "kPoCwfT5jXpr",
        "outputId": "4a28d056-2eae-423b-b5c2-443d12cc9162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Give me working code to do sentiment analysis using transformers\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: To perform sentiment analysis using transformers, we can use the Hugging Face Transformers library. This library provides pre-trained models that can be easily used for various NLP tasks, including sentiment analysis. We'll use the `pipeline` function from the Transformers library to load a pre-trained sentiment analysis model and analyze the sentiment of a given text.\n",
            "\n",
            "Imports: from transformers import pipeline\n",
            "\n",
            "Code:\n",
            "# Load the sentiment-analysis pipeline\n",
            "sentiment_pipeline = pipeline('sentiment-analysis')\n",
            "\n",
            "# Example text for sentiment analysis\n",
            "text = \"I love using transformers for NLP tasks!\"\n",
            "\n",
            "# Perform sentiment analysis\n",
            "result = sentiment_pipeline(text)\n",
            "\n",
            "# Print the result\n",
            "print(result)  # Output will be something like: [{'label': 'POSITIVE', 'score': 0.9998}]\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: RETRY ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'transformers'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: To perform sentiment analysis using transformers, we can use the Hugging Face Transformers library. This library provides pre-trained models that can be easily used for various NLP tasks, including sentiment analysis. We'll use the `pipeline` function from the Transformers library to load a pre-trained sentiment analysis model and analyze the sentiment of a given text.\n",
            "\n",
            "Imports: from transformers import pipeline\n",
            "\n",
            "Code:\n",
            "# First, ensure you have the transformers library installed. You can install it using pip:\n",
            "# !pip install transformers\n",
            "\n",
            "# Load the sentiment-analysis pipeline\n",
            "sentiment_pipeline = pipeline('sentiment-analysis')\n",
            "\n",
            "# Example text for sentiment analysis\n",
            "text = \"I love using transformers for NLP tasks!\"\n",
            "\n",
            "# Perform sentiment analysis\n",
            "result = sentiment_pipeline(text)\n",
            "\n",
            "# Print the result\n",
            "print(result)  # Output will be something like: [{'label': 'POSITIVE', 'score': 0.9998}]\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: RETRY ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'transformers'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "--- GENERATING CODE SOLUTION ---\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is my solution attempt:\n",
            "\n",
            "Description: To perform sentiment analysis using transformers, we can use the Hugging Face Transformers library. This library provides pre-trained models that can be easily used for various NLP tasks, including sentiment analysis. We'll use the `pipeline` function from the Transformers library to load a pre-trained sentiment analysis model and analyze the sentiment of a given text.\n",
            "\n",
            "Imports: from transformers import pipeline\n",
            "\n",
            "Code:\n",
            "# First, ensure you have the transformers library installed. You can install it using pip:\n",
            "# !pip install transformers\n",
            "\n",
            "# Load the sentiment-analysis pipeline\n",
            "sentiment_pipeline = pipeline('sentiment-analysis')\n",
            "\n",
            "# Example text for sentiment analysis\n",
            "text = \"I love using transformers for NLP tasks!\"\n",
            "\n",
            "# Perform sentiment analysis\n",
            "result = sentiment_pipeline(text)\n",
            "\n",
            "# Print the result\n",
            "print(result)  # Output will be something like: [{'label': 'POSITIVE', 'score': 0.9998}]\n",
            "--- CHECKING CODE EXECUTION ---\n",
            "---CODE IMPORT CHECK: FAILED---\n",
            "--- DECISION: FINISH ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Import test failed!\n",
            "                        Here is the exception trace details:\n",
            "                        No module named 'transformers'.\n",
            "\n",
            "                        Please fix the import section.\n",
            "\n",
            "\n",
            "Final Solution:\n",
            "\n",
            "Description:\n",
            "To perform sentiment analysis using transformers, we can use the Hugging Face Transformers library. This library provides pre-trained models that can be easily used for various NLP tasks, including sentiment analysis. We'll use the `pipeline` function from the Transformers library to load a pre-trained sentiment analysis model and analyze the sentiment of a given text.\n",
            "Code:\n",
            "from transformers import pipeline\n",
            "\n",
            "# First, ensure you have the transformers library installed. You can install it using pip:\n",
            "# !pip install transformers\n",
            "\n",
            "# Load the sentiment-analysis pipeline\n",
            "sentiment_pipeline = pipeline('sentiment-analysis')\n",
            "\n",
            "# Example text for sentiment analysis\n",
            "text = \"I love using transformers for NLP tasks!\"\n",
            "\n",
            "# Perform sentiment analysis\n",
            "result = sentiment_pipeline(text)\n",
            "\n",
            "# Print the result\n",
            "print(result)  # Output will be something like: [{'label': 'POSITIVE', 'score': 0.9998}]\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Give me working code to do sentiment analysis using transformers\"\"\"\n",
        "call_reflection_coding_agent(coder_agent, prompt, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aJkj24K1m9x",
      "metadata": {
        "id": "6aJkj24K1m9x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "analytics_vidhya",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "045a5cb3cb4347ccad78fe28e37cb56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b82beadca9f48d88769ab96540d09e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174269ed4b334850b834ad5fc8835ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dfc8fadcba54896a7fbb2237e9fd74d",
            "placeholder": "​",
            "style": "IPY_MODEL_d2e192c6b21b46e6a8788f4a4b5ba92b",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.00kB/s]"
          }
        },
        "2304b2fbdb574ce28ddb3aa0857b125b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a70cdc20a4410c922ace16692206da",
            "placeholder": "​",
            "style": "IPY_MODEL_f132ee49c4a040f4891c525aced7a692",
            "value": " 268M/268M [00:02&lt;00:00, 125MB/s]"
          }
        },
        "2c96baf1be004193bd98b93b23deef04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f0c0a41d0bc4608860f314cde2dadf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f317244ce484f568df200ea3d401346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c08fd0039f540f5848a077014b410d7",
              "IPY_MODEL_6be0a60eebad4b759c4dd9ccbcacc3b8",
              "IPY_MODEL_174269ed4b334850b834ad5fc8835ecc"
            ],
            "layout": "IPY_MODEL_c54f1c082ee24e01a03f27296ad1f926"
          }
        },
        "4358b3ec606940428d00114d795bc982": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470408cd284943998d825ad75f77e876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47e72fae6e8c4f5f9f5508321a87e0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c08fd0039f540f5848a077014b410d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47e72fae6e8c4f5f9f5508321a87e0ca",
            "placeholder": "​",
            "style": "IPY_MODEL_be7521b633b940fda794e388fc859668",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4ef519e3baa449a7952bbb919ac825d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511d77ef6ed043dc8a7a44cf7f610115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869aaf1c022a48e79209719e9998c499",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_540d85ade4bc4a5693cfce545bb3c061",
            "value": 267832558
          }
        },
        "540d85ade4bc4a5693cfce545bb3c061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "588b121da6454b3b8c5d9a71966d01bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f0c0a41d0bc4608860f314cde2dadf0",
            "placeholder": "​",
            "style": "IPY_MODEL_a88e73b9f2af4c58bc44aa1cc8a414fa",
            "value": "model.safetensors: 100%"
          }
        },
        "5c8d93b2c0044cda95f1f3b8b6f4ab9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb53b28433c4e32875fd93e216fc61d",
            "placeholder": "​",
            "style": "IPY_MODEL_b3edcb443c8a4f84b97f1c091a1ba7af",
            "value": "vocab.txt: 100%"
          }
        },
        "5cb53b28433c4e32875fd93e216fc61d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a70cdc20a4410c922ace16692206da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64e47da0c8aa44af835aa0e30150294c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b82beadca9f48d88769ab96540d09e9",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e71e12e226e14fa5a63f8dfbe696aa94",
            "value": 629
          }
        },
        "6be0a60eebad4b759c4dd9ccbcacc3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7808e62088d4878978574c8dcfd9c65",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7838347ac8b4fc38ff1c177c7b29c16",
            "value": 48
          }
        },
        "7a0b493a8f01472c9a61c640e952f0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83ae4bb485104e14abcc6f7c7b60ba3d",
              "IPY_MODEL_64e47da0c8aa44af835aa0e30150294c",
              "IPY_MODEL_ee500f570f304160acb715c6b00cd236"
            ],
            "layout": "IPY_MODEL_bb7d8e1cbb824e73b89ff73a24768cae"
          }
        },
        "83ae4bb485104e14abcc6f7c7b60ba3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeaf0ac3d2bc43c58e78036416217285",
            "placeholder": "​",
            "style": "IPY_MODEL_2c96baf1be004193bd98b93b23deef04",
            "value": "config.json: 100%"
          }
        },
        "869aaf1c022a48e79209719e9998c499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dfc8fadcba54896a7fbb2237e9fd74d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c019623ce542399533684a80090771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7808e62088d4878978574c8dcfd9c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88e73b9f2af4c58bc44aa1cc8a414fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a98ff8e7e03149b8ba8a4df45d64c0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c8d93b2c0044cda95f1f3b8b6f4ab9b",
              "IPY_MODEL_dc95db6884734d9fa24106b23842252f",
              "IPY_MODEL_c303b39b68e244148b4039280d393327"
            ],
            "layout": "IPY_MODEL_aee08eb6ee0245f3bc052705d901f1e1"
          }
        },
        "aee08eb6ee0245f3bc052705d901f1e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3edcb443c8a4f84b97f1c091a1ba7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7838347ac8b4fc38ff1c177c7b29c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb7d8e1cbb824e73b89ff73a24768cae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be7521b633b940fda794e388fc859668": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c303b39b68e244148b4039280d393327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef519e3baa449a7952bbb919ac825d6",
            "placeholder": "​",
            "style": "IPY_MODEL_470408cd284943998d825ad75f77e876",
            "value": " 232k/232k [00:00&lt;00:00, 2.62MB/s]"
          }
        },
        "c54f1c082ee24e01a03f27296ad1f926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e192c6b21b46e6a8788f4a4b5ba92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d37ad6ac566c4df79b8b70fc3cbca94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc95db6884734d9fa24106b23842252f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4358b3ec606940428d00114d795bc982",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d37ad6ac566c4df79b8b70fc3cbca94f",
            "value": 231508
          }
        },
        "e71e12e226e14fa5a63f8dfbe696aa94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eca8a9ab2ccc429e888a369522fa14f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_588b121da6454b3b8c5d9a71966d01bd",
              "IPY_MODEL_511d77ef6ed043dc8a7a44cf7f610115",
              "IPY_MODEL_2304b2fbdb574ce28ddb3aa0857b125b"
            ],
            "layout": "IPY_MODEL_a1c019623ce542399533684a80090771"
          }
        },
        "ee500f570f304160acb715c6b00cd236": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef52b8172f649de919d8f3d68c8cee1",
            "placeholder": "​",
            "style": "IPY_MODEL_045a5cb3cb4347ccad78fe28e37cb56c",
            "value": " 629/629 [00:00&lt;00:00, 23.9kB/s]"
          }
        },
        "eeaf0ac3d2bc43c58e78036416217285": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f132ee49c4a040f4891c525aced7a692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fef52b8172f649de919d8f3d68c8cee1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
